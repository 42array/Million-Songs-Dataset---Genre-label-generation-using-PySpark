{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local').config('spark.executor.memory', '16g') \\\n",
    "    .config('spark.driver.memory', '16g').appName('Generating Genre Labels with LDA').getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel('ERROR')\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper functions:\n",
    "# Define a function that takes in word ids and maps them to the actual words they represent\n",
    "def id2word(topic, num_words, vocab):\n",
    "    result = [vocab[topic[1][i]] for i in range(num_words)]\n",
    "    return result\n",
    "\n",
    "# given the topic distribution for an artist, finds the topic with the maximum probability and assigns the corresponding genre label\n",
    "def label(topic_dist):\n",
    "    topic_idx = list(topic_dist).index(max(topic_dist))\n",
    "    topic_list = df_topics_final[topic_idx]\n",
    "    for k, v in genres.items():\n",
    "        if v == topic_list:\n",
    "            return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in Data...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7078213e2518>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Reading in Data...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MSD_FINAL_me.parquet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'artist_terms'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "print('Reading in Data...')\n",
    "df = spark.read.load('MSD_FINAL_me.parquet')\n",
    "\n",
    "df.select('artist_terms').show()\n",
    "\n",
    "limit_five = f.udf(lambda x: x[:5], ArrayType(StringType()))\n",
    "df = df.withColumn('tokens', limit_five(df['artist_terms']))\n",
    "\n",
    "df.select('tokens').show(truncate=False)\n",
    "\n",
    "vector = CountVectorizer(inputCol='tokens', outputCol='count_vectors')\n",
    "df_cvec_model = vector.fit(df)\n",
    "df_counts = df_cvec_model.transform(df)  # tokens, count_vectors\n",
    "\n",
    "df_counts.select('tokens', 'count_vectors').show()\n",
    "\n",
    "tfidf = IDF(inputCol='count_vectors', outputCol='features')\n",
    "df_tfidf_model = tfidf.fit(df_counts)\n",
    "df_tfidf = df_tfidf_model.transform(df_counts)  # tokens, count_vectors, features\n",
    "\n",
    "df_tfidf.select('tokens', 'count_vectors', 'features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_topics = [3, 5, 8, 10]\n",
    "# number_of_topics = [10]\n",
    "df_topics_final = []\n",
    "df_lda_transformed = None\n",
    "\n",
    "for num_topics in number_of_topics:\n",
    "    max_iter = 50\n",
    "    lda = LDA(seed=1, optimizer=\"em\", k=num_topics, maxIter=max_iter)\n",
    "    df_lda_model = lda.fit(df_tfidf)\n",
    "    df_lda_transformed = df_lda_model.transform(df_tfidf)\n",
    "\n",
    "# Get topics and words\n",
    "    df_topics = df_lda_model.topicsMatrix()\n",
    "    df_vocab = df_cvec_model.vocabulary\n",
    "\n",
    "    num_words = 5  # specify number of words per topic\n",
    "    topic_word_ids = df_lda_model.describeTopics(maxTermsPerTopic=num_words).rdd.map(tuple)  # get ids of words in topics\n",
    "    df_topics_final = topic_word_ids.map(\n",
    "        lambda x: id2word(x, num_words, df_vocab)).collect()  # get the list of words for each topic\n",
    "\n",
    "    for i in range(len(df_topics_final)):\n",
    "        print(\"Topic \" + str(i + 1) + \":\")\n",
    "        print(df_topics_final[i])\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hard coded in order to assign human-understandable labels to the topics\n",
    "genres = {\n",
    "    'reggae': df_topics_final[0],\n",
    "    'blues': df_topics_final[1],\n",
    "    'electronic': df_topics_final[2],\n",
    "    'chill': df_topics_final[3],\n",
    "    'metal': df_topics_final[4],\n",
    "    'country': df_topics_final[5],\n",
    "    'rock': df_topics_final[6],\n",
    "    'pop': df_topics_final[7],\n",
    "    'hip hop': df_topics_final[8],\n",
    "    'latin': df_topics_final[9]\n",
    "}\n",
    "\n",
    "\n",
    "get_genre = f.udf(lambda x: label(x))\n",
    "\n",
    "df_labeled = df_lda_transformed.withColumn('genre', get_genre(df_lda_transformed['topicDistribution']))\n",
    "\n",
    "df_labeled.select('genre').show(truncate=False)\n",
    "\n",
    "df_final = df_labeled.drop('tokens', 'count_vectors', 'features', 'topicDistribution')\n",
    "\n",
    "df_final.select('track_id', 'genre').show()\n",
    "\n",
    "df_final.write.save('MSD_GENRE_me.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
